{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOoILOm-ZEhK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqN89qV4ZEhM"
      },
      "outputs": [],
      "source": [
        "class KNN:\n",
        "    def __init__(self, k=3, distance_metric='euclidean'):\n",
        "        self.k = k\n",
        "        self.distance_metric = distance_metric\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Store the training data as numpy arrays\n",
        "        self.X_train = np.array(X)\n",
        "        self.y_train = np.array(y)\n",
        "\n",
        "    def compute_distance(self, X1, X2):\n",
        "        X1 = np.array(X1).reshape(1, -1)\n",
        "        X2 = np.array(X2)\n",
        "\n",
        "        if self.distance_metric == 'euclidean':\n",
        "            distances = np.linalg.norm(X2 - X1, axis=1)\n",
        "        elif self.distance_metric == 'manhattan':\n",
        "            distances = np.sum(np.abs(X2 - X1), axis=1)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported distance metric: {self.distance_metric}\")\n",
        "        return distances\n",
        "\n",
        "    def predict(self, X):\n",
        "\n",
        "        predictions = []\n",
        "\n",
        "        for x_test in X:\n",
        "            # Compute distances from x_test to all training points\n",
        "            distances = self.compute_distance(x_test, self.X_train)\n",
        "\n",
        "            # Get the indices of the k nearest neighbors\n",
        "            k_indices = np.argsort(distances)[:self.k]\n",
        "\n",
        "            # Get the labels of the k nearest neighbors\n",
        "            k_nearest_labels = self.y_train[k_indices]\n",
        "\n",
        "            # Predict the most common label\n",
        "            prediction = np.bincount(k_nearest_labels.astype(int)).argmax()\n",
        "            predictions.append(prediction)\n",
        "\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"\n",
        "        Predicts the probability of each class (churn or not) using the nearest neighbors.\n",
        "        \"\"\"\n",
        "        proba = []\n",
        "        for x_test in X:\n",
        "            # Compute distances from x_test to all training points\n",
        "            distances = self.compute_distance(x_test, self.X_train)\n",
        "\n",
        "            # Get the indices of the k nearest neighbors\n",
        "            k_indices = np.argsort(distances)[:self.k]\n",
        "\n",
        "            # Get the labels of the k nearest neighbors\n",
        "            k_nearest_labels = self.y_train[k_indices]\n",
        "\n",
        "            # Calculate the probability of class 1 (churn)\n",
        "            proba_class_1 = np.mean(k_nearest_labels)\n",
        "            proba.append(proba_class_1)\n",
        "\n",
        "        return np.array(proba)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHi1QbnJZEhM"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(train_path, test_path):\n",
        "    # Load the datasets\n",
        "    train_data = pd.read_csv(train_path)\n",
        "    test_data = pd.read_csv(test_path)\n",
        "\n",
        "    # Drop irrelevant columns (CustomerId, Surname)\n",
        "    train_data = train_data.drop(columns=['CustomerId', 'Surname','Geography','Gender'], errors='ignore')\n",
        "    test_data = test_data.drop(columns=['CustomerId', 'Surname','Geography','Gender'], errors='ignore')\n",
        "\n",
        "    # Separate features and target in the training data\n",
        "    X_train = train_data.drop(columns=['Exited'])\n",
        "    y_train = train_data['Exited'].astype(int)  # Ensure target labels are integers\n",
        "\n",
        "    # One-Hot Encoding of categorical variables\n",
        "    X_train = pd.get_dummies(X_train, drop_first=True)\n",
        "    X_test = pd.get_dummies(test_data, drop_first=True)\n",
        "\n",
        "    # Align columns of train and test to ensure they have the same columns\n",
        "    X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
        "\n",
        "    # Ensure all columns are numeric\n",
        "    X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
        "    X_test = X_test.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "    # Handle missing values by filling with column means\n",
        "    X_train.fillna(X_train.mean(), inplace=True)\n",
        "    X_test.fillna(X_test.mean(), inplace=True)\n",
        "\n",
        "    # Convert y_train to numpy array\n",
        "    y_train = y_train.values\n",
        "\n",
        "    # Return preprocessed datasets as numpy arrays\n",
        "    return X_train.values, y_train, X_test.values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-Qycf8DZEhN"
      },
      "outputs": [],
      "source": [
        "def cross_validate(X, y, knn, n_splits=5):\n",
        "    \"\"\"\n",
        "    Perform basic K-fold cross-validation using numpy.\n",
        "    \"\"\"\n",
        "    n_samples = len(X)\n",
        "    fold_size = n_samples // n_splits\n",
        "    indices = np.arange(n_samples)\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    accuracy_scores = []\n",
        "\n",
        "    for i in range(n_splits):\n",
        "        # Create train/validation split\n",
        "        val_indices = indices[i * fold_size: (i + 1) * fold_size]\n",
        "        train_indices = np.concatenate([indices[:i * fold_size], indices[(i + 1) * fold_size:]])\n",
        "\n",
        "        X_train, X_val = X[train_indices], X[val_indices]\n",
        "        y_train, y_val = y[train_indices], y[val_indices]\n",
        "\n",
        "        # Fit the model and make predictions\n",
        "        knn.fit(X_train, y_train)\n",
        "        y_pred = knn.predict(X_val)\n",
        "\n",
        "        # Compute accuracy\n",
        "        accuracy = np.mean(y_pred == y_val)\n",
        "        accuracy_scores.append(accuracy)\n",
        "\n",
        "    return np.mean(accuracy_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkJ2E75UbntG"
      },
      "outputs": [],
      "source": [
        "def tune_hyperparameters(X, y, k_values, distance_metrics, n_splits=5):\n",
        "    \"\"\"\n",
        "    Tune hyperparameters k (number of neighbors) and distance metrics using cross-validation.\n",
        "\n",
        "    Parameters:\n",
        "    X (ndarray): Feature matrix (NumPy array).\n",
        "    y (ndarray): Target labels (NumPy array).\n",
        "    k_values (list): List of k values to try.\n",
        "    distance_metrics (list): List of distance metrics to try.\n",
        "    n_splits (int): Number of cross-validation splits.\n",
        "\n",
        "    Returns:\n",
        "    best_k (int): The best k value.\n",
        "    best_metric (str): The best distance metric.\n",
        "    best_score (float): The highest cross-validation score achieved.\n",
        "    \"\"\"\n",
        "    best_k = None\n",
        "    best_metric = None\n",
        "    best_score = -1  # Initialize with a very low score\n",
        "\n",
        "    for k in k_values:\n",
        "        for metric in distance_metrics:\n",
        "            knn = KNN(k=k, distance_metric=metric)\n",
        "            score = cross_validate(X, y, knn, n_splits=5)\n",
        "            print(f\"K: {k}, Metric: {metric}, Cross-Validation Score: {score}\")\n",
        "\n",
        "            # Use accuracy (or another metric) for hyperparameter comparison\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_k = k\n",
        "                best_metric = metric\n",
        "\n",
        "    print(f\"Best K: {best_k}, Best Metric: {best_metric}, Best Score: {best_score}\")\n",
        "    return best_k, best_metric, best_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_yoYDwoZEhN",
        "outputId": "00674cc0-ba25-4a3e-f5a6-b84ee8c008fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: 0.7610666666666666\n",
            "K: 3, Metric: euclidean, Cross-Validation Score: 0.7394\n",
            "K: 3, Metric: manhattan, Cross-Validation Score: 0.7410666666666667\n",
            "K: 5, Metric: euclidean, Cross-Validation Score: 0.7617333333333333\n",
            "K: 5, Metric: manhattan, Cross-Validation Score: 0.762\n",
            "K: 7, Metric: euclidean, Cross-Validation Score: 0.7740666666666667\n",
            "K: 7, Metric: manhattan, Cross-Validation Score: 0.7769333333333333\n",
            "K: 9, Metric: euclidean, Cross-Validation Score: 0.7814\n",
            "K: 9, Metric: manhattan, Cross-Validation Score: 0.7822\n",
            "K: 11, Metric: euclidean, Cross-Validation Score: 0.7863333333333333\n",
            "K: 11, Metric: manhattan, Cross-Validation Score: 0.7880666666666667\n",
            "K: 15, Metric: euclidean, Cross-Validation Score: 0.791\n",
            "K: 15, Metric: manhattan, Cross-Validation Score: 0.7903333333333332\n",
            "K: 21, Metric: euclidean, Cross-Validation Score: 0.7950666666666667\n",
            "K: 21, Metric: manhattan, Cross-Validation Score: 0.7939999999999998\n",
            "K: 30, Metric: euclidean, Cross-Validation Score: 0.7969999999999999\n",
            "K: 30, Metric: manhattan, Cross-Validation Score: 0.7953333333333333\n",
            "K: 60, Metric: euclidean, Cross-Validation Score: 0.7971333333333334\n",
            "K: 60, Metric: manhattan, Cross-Validation Score: 0.7979333333333333\n",
            "Best K: 60, Best Metric: manhattan, Best Score: 0.7979333333333333\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess data\n",
        "X_train, y_train, X_test = preprocess_data('/content/train.csv', '/content/test.csv')\n",
        "\n",
        "# Create and evaluate model\n",
        "knn = KNN(k=5, distance_metric='euclidean')\n",
        "cv_scores = cross_validate(X_train, y_train, knn)\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "\n",
        "k_values = [3, 5, 7, 9, 11, 15, 21, 30, 60]\n",
        "distance_metrics = ['euclidean', 'manhattan']\n",
        "# Perform hyperparameter tuning\n",
        "best_k, best_metric, best_score = tune_hyperparameters(X_train, y_train, k_values, distance_metrics)\n",
        "\n",
        "# TODO: Train on full dataset with optimal hyperparameters and make predictions on test set\n",
        "knn = KNN(k=best_k, distance_metric=best_metric)\n",
        "knn.fit(X_train, y_train)\n",
        "test_predictions = knn.predict_proba(X_test)\n",
        "\n",
        "# Save test predictions\n",
        "pd.DataFrame({'id': pd.read_csv('/content/test.csv')['id'], 'Exited': test_predictions}).to_csv('submissions.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}